\documentclass{sig-alternate} % Mandatory

\begin{document}

\conferenceinfo{ICSE}{'15 Florence}
\title{Drawing Generalizable Conclusions about Software:\\A Sampling Technique and New Spreasheet Corpus}
% \numberofauthors{4}
% \author{
% Yoonki Song, Titus Barik, Brittany Johnson, and Emerson Murphy-Hill\\
% \affaddr{Department of Computer Science}\\
% \affaddr{North Carolina State University}\\
% \affaddr{Raleigh, North Carolina, USA}\\
% \{\href{mailto:ysong2@ncsu.edu}{ysong2},
%   \href{mailto:tbarik@ncsu.edu}{tbarik},
%   \href{mailto:bijohnso@ncsu.edu}{bijohnso}\}@ncsu.edu,
%   \href{mailto:emerson@csc.ncsu.edu}{emerson}@csc.ncsu.edu\\
% }

%-----------------------------------------------------------------------------%
\maketitle

\begin{abstract}
Spreadsheets users are the largest group of software developers on
the planet, and much of what researchers know about this group derives
from the EUSES corpus, a corpus that includes about 5,000 spreadsheets
mined from the internet a decade ago.
While the EUSES corpus has yielded many interesting research results,
researchers have questioned how representative the EUSES corpus is of 
all existing spreadsheets.
In this paper, we introduce a new spreadsheet corpus more than
two orders of magnitude larger than the EUSES corpus
and describe a new sampling techinque that allows researchers to 
create their own open-source corpus that is representative of 
a closed-source corpus.
%TODO what follows is technically an eval -- does our technique produce more representative
%	corpus with respect to three studies?
We illustrate the utility of our corpus and our technique by 
highlighting the differences between corpuses, including by
replicating three small spreadsheet studies on different
corpuses.
%TODO maybe some results, whatever they are
\end{abstract}

\section{Introduction}

Spreadsheets are an important type of software development.
-how many people use them,
-examples of errors and their impact (e.g, Reinhard and Rogoff)

There's existing rich-reasearch on spreadsheets.
Examples.

\subsection{State of the art}
Currently, the most used corpus for spreadsheet analysis is the EUSES corpus. This corpus contains spreadsheets obtained mainly by searching in search engines, so it contains spreadsheets that are publicly available. However, industrial case studies performed by us and other researchers have raised questions about the representativeness of this corpus, as spreadsheets we  encounter in industry tend to be bigger and be more complex. Hence, we believe there is a need for a corpus providing a more realistic test set for spreadsheet researchers.

Where corpus comes from, how it was derived, how many spreadsheets.


Examples, probably from threats sections.
Impact: if not representative, conclusions do not generalize.
Example from prior paper.

In this paper, we present a technique that enables researchers
to draw more generalizable conclusions in their studies.
In a nutshell, the technique involves\ldots

Although this paper focuses on spreadsheets, in reality 
spreadsheets are a microcosm of broader software development,
and consequently the techniques presented here can be used for other 
types of software as well.

The contributions of this paper are:

\begin{itemize}
  \item A technique for creating representative samples of open-source
  		software;
  \item An open-source corpus of spreadsheets more than two orders of magnitude larger
 		than the existing state of the art, along with a never-before analyzed
 		pseudo-closed-source corpus;
  \item A set of distributions of real closed-source spreadsheets that can be
  		used as parameters to our technique; and
  \item An evaluation that suggests our technique can produce more representative
  		results than using the existing state of the art corpus.
\end{itemize}

\section{Prior Work}

Maybe a bit more depth in spreadsheet research, showing how serious it is.

A good bit from Mei Nagappan's representativeness paper~\cite{nag13}.

\section{Our Technique}

Based on that sampling thing represented by the stats professor.

Section closing: talk about you need a good corpus to sample from.

\section{Our Open-Source Corpus}

We took this opportunity to update the old corpus, using roughly similar
methodology.

\subsection{Mining Methodology}

How we mined the web.

\subsection{Corpus Characterization}

Number of spreadsheets, a few stats about them.

Distribution comparison to EUSES here?

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{functions.png}
\caption{Distribution of number of fuctions per spreadsheet, for 3 spreadsheet corpuses.}
\label{fig:effectiveness}
\end{figure}

\section{The Enron Data Set}

While the sample of the Google spreadsheets provides us with a better set than the current EUSES corpus, it still misses the context of real-life industry spreadsheets. Therefore we present a second data set in the paper, derived from the Enron E-mail Archive. This is an large database of over 600,000 emails containing emails from by 158 Enron employees, which was purchased and released by researchers at the University of Massachusetts Amherst. 

\subsection{Data}
First, we requested the most recent version of the dataset, via this form. We got access to v1.3, last updated 29 July, 2013. This version contains 130 folders (one per employee, each containing one or more pst file) with 190 pst files, and is 53 gigs in size.

\subsection{Getting the spreadsheets}
Using the systool's outlook attachment extractor TODO: link, we obtained the spreadsheets from the pst. With the extractor, obtaining all spreadsheets took about 6 hours, on an i7 machine with 16 gig memory. In total, the email set contains 265,586 files (32.3 gigs), of which over 50.000 are Excel files. Among those files are 11.985 unique spreadsheets.

\subsubsection{Analysis}
For all the spreadsheets, we ran the Spreadsheet Scantool, developed at Delft University of Technology. This tool runs on the previously developed Breviz core, made for spreadsheet visualization and smell detection. TODO: References. 11.136 spreadsheets could be analyzed, the others were corrupt, password protected, or otherwise unreadable.

\subsection{The spreadsheets}
\subsubsection{Worksheets}
In total, the 11.136 spreadsheets contain 49,872 worksheets. This is a aveage of 4.4 worksheets per spreadsheet. Most spreadsheets have 3 worksheets, most likely because this is the default number of worksheets in 

\section{Conclusion}

\section{Distributions from Real Closed-Source Code}

Describe dataset.
Talk about distribution. (plot distribution on same axis, maybe three different metrics).

\section{Evaluation}

RQ1: Are distributions statistically significantly different for the spreadsheet sets discussed here?
RQ2: Do the conclusions from existing studies change depending on what corpus they use? (Compare uses to others)
RQ3: Do conclusions drawn using our sampling technique better approximate conclusions from original sample?

\section{Limtations}

Limitations of both the technique, and the study.

\section{Conclusions}

\end{document}
